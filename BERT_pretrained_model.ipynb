{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cedro3/BERT/blob/master/BERT_pretrained_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hbrU6dgi0K3"
   },
   "source": [
    "# 日本語事前学習済みBERTで色々試してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsVKbPGPlhA1"
   },
   "source": [
    "# セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "9chnu67trMpe",
    "outputId": "edfab473-3d62-4271-f6e7-1a748bbc5aab"
   },
   "outputs": [],
   "source": [
    "# モジュールインストール\n",
    "!pip install pyknp\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iN1CgL7src62",
    "outputId": "93a57e7b-f5c1-4b10-8393-6c31b34e15fc"
   },
   "outputs": [],
   "source": [
    "# JUMMAN++ インストール（5分ほどかかります)\n",
    "!wget https://github.com/ku-nlp/jumanpp/releases/download/v2.0.0-rc2/jumanpp-2.0.0-rc2.tar.xz\n",
    "!tar xfv jumanpp-2.0.0-rc2.tar.xz  \n",
    "%cd jumanpp-2.0.0-rc2\n",
    "!mkdir bld\n",
    "%cd bld\n",
    "!cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local\n",
    "!make install -j2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9blGWuKfmmOi"
   },
   "outputs": [],
   "source": [
    "# 日本語学習済みBERTモデルをダウンロード　（10分ほどかかります）\n",
    "import urllib.request\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# ディレクトリー作成\n",
    "os.chdir('/content')\n",
    "os.makedirs('bert', exist_ok = True)\n",
    "\n",
    "# zipファイルダウンロード\n",
    "url = 'http://nlp.ist.i.kyoto-u.ac.jp/DLcounter/lime.cgi?down=http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JapaneseBertPretrainedModel/Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip&name=Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip'\n",
    "title = './bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip'\n",
    "urllib.request.urlretrieve(url,\"{0}\".format(title))\n",
    "\n",
    "# zipファイル解凍\n",
    "zipf = zipfile.ZipFile('./bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip')\n",
    "zipf.extractall('./bert/')\n",
    "zipf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQbTd7drl1E8"
   },
   "source": [
    "# コード本体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "lAZikwgNvTGh",
    "outputId": "fc38a318-8969-4182-8156-1e5198cb9b9a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertConfig\n",
    "import numpy as np\n",
    "import textwrap\n",
    "config = BertConfig.from_json_file('./bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/config.json')\n",
    "model = BertForMaskedLM.from_pretrained('./bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/pytorch_model.bin', config=config)\n",
    "bert_tokenizer = BertTokenizer('./bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/vocab.txt',\n",
    " do_lower_case=False, do_basic_tokenize=False)\n",
    "from pyknp import Juman\n",
    "jumanpp = Juman()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tu1Y6GaD9WMH"
   },
   "outputs": [],
   "source": [
    "# テキストへ[CLS],[SEP],[MASK]を追加する関数\n",
    "def preparation(tokenized_text):\n",
    "    \n",
    "    # [CLS],[SEP]の挿入\n",
    "    tokenized_text.insert(0, '[CLS]')  # センテンスの先頭に[CLS]を付ける\n",
    "    tokenized_text.append('[SEP]')  # センテンスの最後に[SEP]を付ける \n",
    "        \n",
    "    maru = []\n",
    "    for i, word in enumerate(tokenized_text):\n",
    "        if word =='。' and i !=len(tokenized_text)-2:  # 「。」の位置検出\n",
    "            maru.append(i)\n",
    "\n",
    "    for i, loc in enumerate(maru):\n",
    "        tokenized_text.insert(loc+1+i, '[SEP]')  # 文の「。」の次に[SEP]を挿入する\n",
    "        \n",
    "    # □を[MASK]に置き換え　\n",
    "    mask_index = []\n",
    "    for index, word in enumerate(tokenized_text):\n",
    "        if word =='□':  # 「□」の位置検出\n",
    "            tokenized_text[index] = '[MASK]'\n",
    "            mask_index.append(index)\n",
    "    \n",
    "    return tokenized_text, mask_index  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gl0iNxZfnSK0"
   },
   "source": [
    "# BERTはセンター試験を解けるか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wmogQFJy36A"
   },
   "outputs": [],
   "source": [
    "# テキストをIDテンソルに変換\n",
    "text = \"ギリシア人ポリュビオスは，著書『歴史』の中で，ローマ共和政の国制（政治体制）を優れたものと評価している。彼によれば，その国制には，コンスルという王制的要素，元老院という□制的要素，民衆という民主制的要素が存在しており，これら三者が互いに協調や牽制をしあって均衡しているというのである。ローマ人はこの政治体制を誇りとしており，それは，彼らが自らの国家を指して呼んだ「ローマの元老院と民衆」という名称からも読み取ることができる。共和政期末の内戦を勝ち抜いたかに見えた□でさえも，この体制を壊そうとしているという疑いをかけれ，暗殺されてしまった。\"\n",
    "result = jumanpp.analysis(text)  # 分かち書き\n",
    "tokenized_text = [mrph.midasi for mrph in result.mrph_list()]  # 単語リストに変換\n",
    "tokenized_text, mask_index = preparation(tokenized_text)  # [CLS],[SEP],[MASK]の追加\n",
    "tokens = bert_tokenizer.convert_tokens_to_ids(tokenized_text)  # IDリストに変換\n",
    "tokens_tensor = torch.tensor([tokens])  # IDテンソルに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "X98fIZNsxzf1",
    "outputId": "3187fb71-b5fc-4572-b757-9e6ec73628a4"
   },
   "outputs": [],
   "source": [
    "# [MASK]箇所を推論(TOP5)\n",
    "model.eval() \n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "model.to('cuda')\n",
    "print(textwrap.fill(text, 45))\n",
    "print()\n",
    "\n",
    "with torch.no_grad():\n",
    "  outputs = model(tokens_tensor)\n",
    "  predictions = outputs[0]\n",
    "  \n",
    "  for i in range(len(mask_index)):\n",
    "     _, predicted_indexes = torch.topk(predictions[0, mask_index[i]], k=5)\n",
    "     predicted_tokens = bert_tokenizer.convert_ids_to_tokens(predicted_indexes.tolist())\n",
    "     print(i, predicted_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D99xgC_fiix8"
   },
   "source": [
    "# BERTによる文生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f56ywdkp8XzC"
   },
   "outputs": [],
   "source": [
    "# 形態素解析\n",
    "text = \"我々が10年以内に月に行こうなどと決めたのは、それが容易だからではありません。むしろ困難だからです。この目標が、我々のもつ行動力や技術の最善といえるものを集結しそれがどれほどのものかを知るのに役立つこととなるからです。その挑戦こそ、我々が受けて立つことを望み、先延ばしすることを望まないものだからです。そして、これこそが、我々が勝ち取ろうと志すものであり、我々以外にとってもそうだからです。\"\n",
    "result = jumanpp.analysis(text)  # 分かち書き\n",
    "tokenized_text = [mrph.midasi for mrph in result.mrph_list()]  # 単語リストに変換\n",
    "tokenized_text, mask_index = preparation(tokenized_text)  # [CLS],[SEP]の追加\n",
    "tokens = bert_tokenizer.convert_tokens_to_ids(tokenized_text)  # IDリストに変換\n",
    "tokens_tensor = torch.tensor([tokens])  # IDテンソルに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRpqBAJD8X2d"
   },
   "outputs": [],
   "source": [
    "# 1単語予測関数\n",
    "def predict_one(tokens_tensor, mask_index):\n",
    "\n",
    "    model.eval()    \n",
    "    tokens_tensor = tokens_tensor.to('cuda')\n",
    "    model.to('cuda')\n",
    " \n",
    "    with torch.no_grad():\n",
    "      outputs = model(tokens_tensor)\n",
    "      predictions = outputs[0]\n",
    " \n",
    "      _, predicted_indexes = torch.topk(predictions[0, mask_index], k=5)\n",
    "      predicted_tokens = bert_tokenizer.convert_ids_to_tokens(predicted_indexes.tolist())\n",
    "    return predicted_tokens, predicted_indexes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "f_Vjz7r-8X54",
    "outputId": "f27b8a62-9004-4505-abf5-0795dc7cfd5f"
   },
   "outputs": [],
   "source": [
    "# 文生成\n",
    "for i in range(1,len(tokens_tensor[0])):\n",
    "    tmp = torch.tensor(tokens_tensor)  # tokens_tensorをtmpにコピー\n",
    "    tmp[0, i]=4  # i番目を[mask]に書き換え\n",
    "    predicted_tokens, predicted_indexes =predict_one(tmp, i)  # [mask]を予測\n",
    "    if predicted_indexes !=1:  # 予測が[UNK]でなければ\n",
    "      tokens_tensor[0, i] = predicted_indexes[0]  # 予測IDの[0]番目でtokens_tensorのi番目を上書きする\n",
    "\n",
    "target_list = tokens_tensor.tolist()[0]  \n",
    "predict_list = bert_tokenizer.convert_ids_to_tokens(target_list)  \n",
    "predict_sentence = ''.join(predict_list[1:])\n",
    "\n",
    "print('------ original_text -------')\n",
    "print(textwrap.fill(text,45))\n",
    "print('------ predict_text -------')\n",
    "print(textwrap.fill(predict_sentence,45))  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPHs9Aq21BBE3x7qkVwXKaN",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BERT_pretrained_model",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
